from os import listdir, path
import numpy as np
import scipy, cv2, os, sys, argparse
import json, subprocess, random, string
from tqdm import tqdm
from glob import glob
import torch
import pickle
import shutil 
from ultralytics import YOLO

parser = argparse.ArgumentParser(description='Wav2Lipæ¨¡å‹è§†é¢‘å¤„ç†ç¨‹åº')
parser.add_argument('--img_size', default=256, type=int, help='è¾“å‡ºäººè„¸å›¾ç‰‡å°ºå¯¸')
parser.add_argument('--avatar_id', default='wav2lip_avatar1', type=str, help='è§’è‰²å')
parser.add_argument('--avatar_base_dir', default='../data/avatars', type=str, help='å¤´åƒæ•°æ®å­˜å‚¨åŸºç¡€ç›®å½•')
parser.add_argument('--video_path', default='', type=str, help='è¾“å…¥è§†é¢‘è·¯å¾„')
parser.add_argument('--batch_frames', type=int, default=150,
                    help='æ¯æ‰¹å¤„ç†çš„å¸§æ•°ï¼Œå†…å­˜ä¸è¶³æ—¶å¯è°ƒå°æ­¤å€¼')
parser.add_argument('--use_video2imgs', action='store_true',
                    help='ä½¿ç”¨åŸæ¥çš„video2imgsæ–¹å¼å¤„ç†è§†é¢‘')
parser.add_argument('--nosmooth', default=False, action='store_true',
                    help='æ˜¯å¦å…³é—­äººè„¸æ¡†å¹³æ»‘å¤„ç†')
parser.add_argument('--pads', nargs='+', type=int, default=[0, 10, 0, 0], 
                    help='äººè„¸åŒºåŸŸå¡«å……å€¼ (ä¸Š, ä¸‹, å·¦, å³)ï¼Œå»ºè®®è°ƒæ•´ä»¥åŒ…å«ä¸‹å·´')
parser.add_argument('--face_det_batch_size', type=int, 
                    help='äººè„¸æ£€æµ‹çš„æ‰¹å¤„ç†å¤§å°', default=6)
parser.add_argument('--resize_factor', type=float, default=1.0,
                    help='è°ƒæ•´è¾“å…¥å›¾åƒå¤§å°çš„å› å­ï¼Œå€¼å°äº1å¯å‡å°‘å†…å­˜ä½¿ç”¨')
parser.add_argument('--force_cpu', action='store_true',
                    help='å¼ºåˆ¶ä½¿ç”¨CPUè¿›è¡Œæ¨ç†ï¼Œè§£å†³CUDAå…¼å®¹æ€§é—®é¢˜')
args = parser.parse_args()

# ç¡®å®šä½¿ç”¨çš„è®¾å¤‡
if args.force_cpu:
    device = 'cpu'
    print('å¼ºåˆ¶ä½¿ç”¨CPUè¿›è¡Œæ¨ç†')
else:
    # å³ä½¿æœ‰CUDAå¯ç”¨ï¼Œä¹Ÿå°è¯•æ£€æµ‹æ˜¯å¦æœ‰å…¼å®¹æ€§é—®é¢˜
    try:
        print('æ£€æµ‹CUDAå…¼å®¹æ€§...')
        # å°è¯•åœ¨CUDAä¸Šè¿›è¡Œä¸€ä¸ªç®€å•æ“ä½œ
        if torch.cuda.is_available():
            test_tensor = torch.zeros(1).cuda()
            test_tensor = test_tensor + 1
            # å°è¯•è¿›è¡ŒNMSæ“ä½œï¼Œå¯èƒ½ä¼šå¤±è´¥
            try:
                from torchvision.ops import nms
                boxes = torch.tensor([[0, 0, 1, 1], [0, 0, 1, 1]]).cuda().float()
                scores = torch.tensor([0.9, 0.8]).cuda()
                nms(boxes, scores, 0.5)
                device = 'cuda'
                print('ä½¿ç”¨CUDAè¿›è¡Œæ¨ç†')
            except Exception as e:
                print(f'CUDA NMSæ“ä½œä¸æ”¯æŒ: {e}')
                device = 'cpu'
                print('ç”±äºNMSå…¼å®¹æ€§é—®é¢˜ï¼Œåˆ‡æ¢åˆ°CPUè¿›è¡Œæ¨ç†')
        else:
            device = 'cpu'
            print('æœªæ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨CPUè¿›è¡Œæ¨ç†')
    except Exception as e:
        device = 'cpu'
        print(f'CUDAæµ‹è¯•å¤±è´¥: {e}ï¼Œä½¿ç”¨CPUè¿›è¡Œæ¨ç†')

# åˆå§‹åŒ–YOLOæ¨¡å‹ - å§‹ç»ˆåœ¨CPUä¸ŠåŠ è½½æ¨¡å‹ï¼Œéœ€è¦æ—¶å†è½¬ç§»åˆ°CUDA
# ä½¿ç”¨ç»å¯¹è·¯å¾„ç¡®ä¿æ¨¡å‹æ–‡ä»¶èƒ½è¢«æ‰¾åˆ°
import os
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(script_dir)
yolo_model_path = os.path.join(project_root, 'models', 'yolo', 'yolov8n-face.pt')

if not os.path.exists(yolo_model_path):
    # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
    alternative_paths = [
        os.path.join(project_root, 'models', 'yolo', 'yolov8n-face.pt'),
        os.path.join(os.getcwd(), 'models', 'yolo', 'yolov8n-face.pt'),
        'models/yolo/yolov8n-face.pt',
        '../models/yolo/yolov8n-face.pt',
        '../../models/yolo/yolov8n-face.pt'
    ]
    
    for path in alternative_paths:
        if os.path.exists(path):
            yolo_model_path = path
            break
    else:
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°YOLOæ¨¡å‹æ–‡ä»¶ã€‚å°è¯•è¿‡çš„è·¯å¾„: {alternative_paths}")

print(f"ä½¿ç”¨YOLOæ¨¡å‹æ–‡ä»¶: {yolo_model_path}")
face_det = YOLO(yolo_model_path)
if device == 'cpu':
    # ç¡®ä¿æ¨¡å‹åœ¨CPUä¸Š
    face_det.to('cpu')
else:
    # å°è¯•å°†æ¨¡å‹è½¬ç§»åˆ°CUDA
    try:
        face_det.to('cuda')
    except Exception as e:
        print(f'å°†æ¨¡å‹è½¬ç§»åˆ°CUDAå¤±è´¥: {e}ï¼Œä½¿ç”¨CPUä»£æ›¿')
        device = 'cpu'
        face_det.to('cpu')

def osmakedirs(path_list):
    for path in path_list:
        os.makedirs(path) if not os.path.exists(path) else None

def video2imgs(vid_path, save_path, ext='.jpg', cut_frame=10000000):
    print(f"å³å°†ä½¿ç”¨OpenCVå°†è§†é¢‘: {vid_path} è½¬æ¢ä¸ºå›¾ç‰‡")
    cap = cv2.VideoCapture(vid_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    print(f"æ£€æµ‹åˆ°è§†é¢‘å¸§ç‡: {fps}, æ€»å¸§æ•°: {frame_count}, é¢„è®¡æ—¶é•¿: {frame_count/fps if fps else 0:.2f}ç§’")
    count = 0
    while True:
        if count >= frame_count or count > cut_frame:
            break
        ret, frame = cap.read()
        if ret:
            cv2.imwrite(f"{save_path}/{count:08d}{ext}", frame)
            count += 1
        else:
            break
    print("è§†é¢‘è½¬æ¢å®Œæˆ")

def read_imgs(img_list):
    frames = []
    print('è¯»å–å›¾ç‰‡åˆ°å†…å­˜...')
    for img_path in tqdm(img_list):
        frame = cv2.imread(img_path)
        frames.append(frame)
    return frames

def get_smoothened_boxes(boxes, T):
	for i in range(len(boxes)):
		if i + T > len(boxes):
			window = boxes[len(boxes) - T:]
		else:
			window = boxes[i : i + T]
		boxes[i] = np.mean(window, axis=0)
	return boxes

def face_detect(images):
    print('å³å°†å¼€å§‹äººè„¸æ£€æµ‹...')
    predictions = []
    global device, face_det  # å…¨å±€å˜é‡ï¼Œå¯èƒ½éœ€è¦ä¿®æ”¹
    total_batches = len(images) // args.face_det_batch_size + (1 if len(images) % args.face_det_batch_size != 0 else 0)
    
    print(f"progress:æ€»å…±éœ€è¦å¤„ç† {total_batches} æ‰¹æ¬¡")
    
    for batch_idx in range(0, len(images), args.face_det_batch_size):
        try:
            current_batch = images[batch_idx:batch_idx + args.face_det_batch_size]
            print(f"progress:æ­£åœ¨å¤„ç†ç¬¬ {batch_idx//args.face_det_batch_size + 1}/{total_batches} æ‰¹æ¬¡ï¼Œå…± {len(current_batch)} å¸§")
            
            # ä½¿ç”¨YOLOå¤„ç†å½“å‰æ‰¹æ¬¡
            batch_predictions = []
            for img in current_batch:
                # å¦‚æœæŒ‡å®šäº†resize_factorï¼Œè°ƒæ•´å›¾åƒå¤§å°
                if args.resize_factor != 1.0:
                    h, w = img.shape[:2]
                    new_h, new_w = int(h * args.resize_factor), int(w * args.resize_factor)
                    resized_img = cv2.resize(img, (new_w, new_h))
                    # åœ¨ç¼©å°å›¾åƒä¸Šæ£€æµ‹äººè„¸
                    results = face_det(resized_img, conf=0.01, iou=0.5, device=device)[0]
                    boxes = results.boxes.xyxy.cpu().numpy()
                    # å°†åæ ‡æ˜ å°„å›åŸå§‹å¤§å°
                    if len(boxes) > 0:
                        # ç¡®ä¿æ˜¯å¯ä¿®æ”¹çš„æ•°ç»„
                        boxes = boxes.copy()
                        boxes[:, [0, 2]] = boxes[:, [0, 2]] / args.resize_factor
                        boxes[:, [1, 3]] = boxes[:, [1, 3]] / args.resize_factor
                        # ç¡®ä¿åæ ‡æ˜¯æœ‰æ•ˆçš„
                        h, w = img.shape[:2]
                        box = boxes[0]  # å–ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„äººè„¸
                        # ç¡®ä¿æ¡†åœ¨å›¾åƒèŒƒå›´å†…
                        box[0] = max(0, min(box[0], w-1))
                        box[1] = max(0, min(box[1], h-1))
                        box[2] = max(box[0]+1, min(box[2], w))
                        box[3] = max(box[1]+1, min(box[3], h))
                        batch_predictions.append(box)  # å–ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„äººè„¸
                    else:
                        batch_predictions.append(None)
                else:
                    # åœ¨åŸå›¾ä¸Šæ£€æµ‹
                    results = face_det(img, conf=0.01, iou=0.5, device=device)[0]
                    boxes = results.boxes.xyxy.cpu().numpy()
                    if len(boxes) > 0:
                        batch_predictions.append(boxes[0])  # å–ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„äººè„¸
                    else:
                        batch_predictions.append(None)
            
            predictions.extend(batch_predictions)
            
            # è¾“å‡ºè¿›åº¦
            progress = int((batch_idx + len(current_batch)) / len(images) * 100)
            print(f"progress:äººè„¸æ£€æµ‹è¿›åº¦: {progress}%")
            
        except Exception as e:
            error_str = str(e)
            print(f"progress:å¤„ç†å‡ºç°é”™è¯¯: {error_str}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯CUDAå…¼å®¹æ€§é—®é¢˜
            if "torchvision::nms" in error_str or "CUDA" in error_str:
                if device == "cuda":
                    print("progress:æ£€æµ‹åˆ°CUDAå…¼å®¹æ€§é—®é¢˜ï¼Œåˆ‡æ¢åˆ°CPU")
                    device = 'cpu'
                    face_det.to('cpu')
                    # é‡è¯•å½“å‰æ‰¹æ¬¡
                    batch_idx -= args.face_det_batch_size
                    continue
            
            # å†…å­˜ä¸è¶³é—®é¢˜å¤„ç†
            if args.face_det_batch_size > 1:
                # å‡å°æ‰¹æ¬¡å¤§å°å¹¶é‡è¯•
                args.face_det_batch_size = max(1, args.face_det_batch_size // 2)
                print(f'progress:æ£€æµ‹åˆ°å†…å­˜æº¢å‡ºï¼Œå‡å°æ‰¹å¤„ç†å¤§å°ä¸º: {args.face_det_batch_size}')
                predictions = predictions[:batch_idx]  # ä¿ç•™å·²å¤„ç†çš„ç»“æœ
                batch_idx -= args.face_det_batch_size  # å›é€€åˆ°ä¸Šä¸€ä¸ªæ‰¹æ¬¡
                continue
            elif args.resize_factor > 0.1:
                # æ‰¹å¤„ç†å¤§å°å·²ä¸º1ï¼Œå°è¯•å‡å°å›¾åƒå¤§å°
                old_factor = args.resize_factor
                args.resize_factor *= 0.5
                print(f"progress:æ‰¹å¤„ç†å¤§å°å·²ä¸º1ï¼Œå°è¯•å°†resize_factorä»{old_factor}å‡å°åˆ°{args.resize_factor}")
                batch_idx -= args.face_det_batch_size
                continue
            else:
                # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†
                print(f"progress:å¤„ç†å¤±è´¥ï¼Œå·²å°è¯•æ‰€æœ‰å¯èƒ½çš„ä¼˜åŒ–æ–¹æ³•")
                raise RuntimeError(f'å¤„ç†å¤±è´¥: {error_str}ã€‚è¯·å°è¯•ä½¿ç”¨æ›´å°çš„è§†é¢‘æˆ–æ›´ä½åˆ†è¾¨ç‡çš„è§†é¢‘ã€‚')

    results = []
    pady1, pady2, padx1, padx2 = args.pads
    
    print('progress:å¼€å§‹å¤„ç†æ£€æµ‹ç»“æœ...')
    for i, (rect, image) in enumerate(zip(predictions, images)):
        if rect is None:
            cv2.imwrite('temp/faulty_frame.jpg', image)
            raise ValueError('æœªæ£€æµ‹åˆ°äººè„¸ï¼è¯·ç¡®ä¿è§†é¢‘ä¸­æ‰€æœ‰å¸§éƒ½åŒ…å«äººè„¸ã€‚')

        # ç¡®ä¿åæ ‡æ˜¯æµ®ç‚¹æ•°ï¼Œä»¥ä¾¿äºå¹³æ»‘å¤„ç†
        y1 = float(max(0, rect[1] - pady1))
        y2 = float(min(image.shape[0], rect[3] + pady2))
        x1 = float(max(0, rect[0] - padx1))
        x2 = float(min(image.shape[1], rect[2] + padx2))
        
        # æ£€æŸ¥æ¡†æ˜¯å¦æœ‰æ•ˆ
        if not (0 <= y1 < y2 <= image.shape[0] and 0 <= x1 < x2 <= image.shape[1]):
            print(f"è­¦å‘Šï¼šæ£€æµ‹åˆ°æ— æ•ˆçš„äººè„¸æ¡† [{x1},{y1},{x2},{y2}]ï¼Œè°ƒæ•´åˆ°æœ‰æ•ˆèŒƒå›´")
            y1 = float(max(0, min(y1, image.shape[0]-1)))
            y2 = float(max(y1+1, min(y2, image.shape[0])))
            x1 = float(max(0, min(x1, image.shape[1]-1)))
            x2 = float(max(x1+1, min(x2, image.shape[1])))
        
        results.append([x1, y1, x2, y2])
        
        if i % 10 == 0:  # æ¯å¤„ç†10å¸§è¾“å‡ºä¸€æ¬¡è¿›åº¦
            progress = int((i + 1) / len(predictions) * 100)
            print(f"progress:ç»“æœå¤„ç†è¿›åº¦: {progress}%")

    boxes = np.array(results)
    if not args.nosmooth: 
        print('progress:æ­£åœ¨å¹³æ»‘å¤„ç†äººè„¸æ¡†...')
        boxes = get_smoothened_boxes(boxes, T=5)
    
    print('progress:æ­£åœ¨ç”Ÿæˆæœ€ç»ˆç»“æœ...')
    # ç¡®ä¿åæ ‡éƒ½æ˜¯æ•´æ•°
    results = []
    for image, (x1, y1, x2, y2) in zip(images, boxes):
        # å°†æµ®ç‚¹æ•°è½¬æ¢ä¸ºæ•´æ•°
        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
        # ç¡®ä¿è¾¹ç•Œä¸è¶…å‡ºå›¾åƒèŒƒå›´
        y1 = max(0, y1)
        y2 = min(image.shape[0], y2)
        x1 = max(0, x1)
        x2 = min(image.shape[1], x2)
        # ç¡®ä¿åŒºåŸŸæœ‰æ•ˆï¼ˆå®½é«˜å¤§äº0ï¼‰
        if y2 <= y1 or x2 <= x1:
            print(f"è­¦å‘Šï¼šæ£€æµ‹åˆ°æ— æ•ˆçš„äººè„¸æ¡† [{x1},{y1},{x2},{y2}]ï¼Œä½¿ç”¨æ•´ä¸ªå›¾åƒ")
            y1, x1 = 0, 0
            y2, x2 = image.shape[0], image.shape[1]
        
        try:
            face_region = image[y1:y2, x1:x2]
            results.append([face_region, (y1, y2, x1, x2)])
        except Exception as e:
            print(f"è­¦å‘Šï¼šè£å‰ªäººè„¸åŒºåŸŸæ—¶å‡ºé”™: {e}ï¼Œåæ ‡: [{x1},{y1},{x2},{y2}]ï¼Œå›¾åƒå¤§å°: {image.shape}")
            # ä½¿ç”¨æ•´ä¸ªå›¾åƒä½œä¸ºå¤‡é€‰
            results.append([image, (0, image.shape[0], 0, image.shape[1])])

    print('progress:äººè„¸æ£€æµ‹å®Œæˆ')
    return results

def process_video_batch(frames, face_imgs_path, start_idx):
    print(f"progress:æ­£åœ¨å¤„ç†ç¬¬ {start_idx} - {start_idx + len(frames)} å¸§...")
    face_det_results = face_detect(frames)
    coord_list = []
    idx = start_idx
    print(f"progress:æœ¬æ‰¹æ¬¡æ£€æµ‹åˆ°{len(face_det_results)}å¼ äººè„¸")
    for i, (frame, coords) in enumerate(face_det_results):
        resized_crop_frame = cv2.resize(frame, (args.img_size, args.img_size))
        cv2.imwrite(f"{face_imgs_path}/{idx:08d}.png", resized_crop_frame)
        coord_list.append(coords)
        idx += 1
        if i % 10 == 0:  # æ¯å¤„ç†10å¸§è¾“å‡ºä¸€æ¬¡è¿›åº¦
            progress = int((i / len(face_det_results)) * 100)
            print(f"progress:{progress}%")
    return coord_list

def clean_directory(directory):
    """æ¸…ç©ºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•"""
    if os.path.exists(directory):
        print(f"æ¸…ç†ç›®å½•: {directory}")
        shutil.rmtree(directory)
    os.makedirs(directory)

if __name__ == "__main__":
    try:
        # æ‰“å°æ‰€æœ‰å‚æ•°åˆ°æ—¥å¿—
        print("=" * 80)
        print("ğŸ“‹ Wav2Lipè§†é¢‘å¤„ç†å‚æ•°é…ç½®:")
        print("=" * 80)
        print(f"  ğŸ­ è§’è‰²åç§° (avatar_id): {args.avatar_id}")
        print(f"  ğŸ“ å¤´åƒåŸºç¡€ç›®å½• (avatar_base_dir): {args.avatar_base_dir}")
        print(f"  ğŸ¬ è¾“å…¥è§†é¢‘è·¯å¾„ (video_path): {args.video_path}")
        print(f"  ğŸ“ è¾“å‡ºå›¾ç‰‡å°ºå¯¸ (img_size): {args.img_size}x{args.img_size}")
        print(f"  ğŸ“¦ æ‰¹å¤„ç†å¸§æ•° (batch_frames): {args.batch_frames}")
        print(f"  ğŸ” äººè„¸æ£€æµ‹æ‰¹å¤§å° (face_det_batch_size): {args.face_det_batch_size}")
        print(f"  ğŸ“ å›¾åƒç¼©æ”¾å› å­ (resize_factor): {args.resize_factor}")
        print(f"  ğŸ”² äººè„¸å¡«å……å€¼ (pads): ä¸Š={args.pads[0]}, ä¸‹={args.pads[1]}, å·¦={args.pads[2]}, å³={args.pads[3]}")
        print(f"  ğŸ¯ ä½¿ç”¨video2imgsæ¨¡å¼ (use_video2imgs): {args.use_video2imgs}")
        print(f"  ğŸ”„ å…³é—­å¹³æ»‘å¤„ç† (nosmooth): {args.nosmooth}")
        print(f"  ğŸ’» å¼ºåˆ¶ä½¿ç”¨CPU (force_cpu): {args.force_cpu}")
        print(f"  âš™ï¸  å®é™…ä½¿ç”¨è®¾å¤‡ (device): {device}")
        print("=" * 80)
        
        # åˆ›å»ºtempç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if not os.path.exists('temp'):
            os.makedirs('temp')
            
        avatar_path = f"{args.avatar_base_dir}/{args.avatar_id}"
        full_imgs_path = f"{avatar_path}/full_imgs" 
        face_imgs_path = f"{avatar_path}/face_imgs" 
        coords_path = f"{avatar_path}/coords.pkl"
        
        print(f"progress:å½¢è±¡è·¯å¾„: {avatar_path}ï¼Œåˆ‡å›¾è·¯å¾„: {full_imgs_path}ï¼Œäººè„¸åˆ‡å›¾è·¯å¾„: {face_imgs_path}ï¼Œåæ ‡è·¯å¾„: {coords_path}")

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        osmakedirs([avatar_path, full_imgs_path, face_imgs_path])

        # æ¸…ç†æ—§æ–‡ä»¶
        print("progress:å¼€å§‹æ¸…ç†æ—§æ–‡ä»¶...")
        clean_directory(full_imgs_path)
        clean_directory(face_imgs_path)
        if os.path.exists(coords_path):
            os.remove(coords_path)
            print(f"progress:å·²åˆ é™¤æ—§çš„åæ ‡æ–‡ä»¶: {coords_path}")

        if args.use_video2imgs:
            # ä½¿ç”¨åŸæ¥çš„å¤„ç†æ–¹å¼
            print("progress:ä½¿ç”¨video2imgsæ–¹å¼å¤„ç†è§†é¢‘...")
            video2imgs(args.video_path, full_imgs_path, ext='.jpg')
            input_img_list = sorted(glob(os.path.join(full_imgs_path, '*.jpg')))
            frames = read_imgs(input_img_list)
            face_det_results = face_detect(frames)
            coord_list = []
            idx = 0
            print(f"progress:å…±æ£€æµ‹åˆ°{len(face_det_results)}å¼ äººè„¸")
            total = len(face_det_results)
            for i, (frame, coords) in enumerate(face_det_results):
                resized_crop_frame = cv2.resize(frame, (args.img_size, args.img_size))
                cv2.imwrite(f"{face_imgs_path}/{idx:08d}.png", resized_crop_frame)
                coord_list.append(coords)
                idx += 1
                if i % 10 == 0:  # æ¯å¤„ç†10å¸§è¾“å‡ºä¸€æ¬¡è¿›åº¦
                    progress = int((i / total) * 100)
                    print(f"progress:{progress}%")
            
            print(f"progress:æ­£åœ¨å†™å…¥åæ ‡æ•°æ®åˆ°æ–‡ä»¶: {coords_path}")
            with open(coords_path, 'wb') as f:
                pickle.dump(coord_list, f)
            print(f"progress:å¤„ç†å®Œæˆ! å…±å¤„ç†äº† {idx} å¸§")
        else:
            # ä½¿ç”¨æ–°çš„åˆ†æ‰¹å¤„ç†æ–¹å¼
            cap = cv2.VideoCapture(args.video_path)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            print(f"progress:è§†é¢‘æ€»å¸§æ•°: {total_frames}")
            
            all_coords = []
            batch_frames = []
            frame_count = 0
            batch_count = 0
            
            print("progress:å¼€å§‹åˆ†æ‰¹å¤„ç†è§†é¢‘...")
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # ä¿å­˜å®Œæ•´å¸§
                cv2.imwrite(f"{full_imgs_path}/{frame_count:08d}.png", frame)
                
                batch_frames.append(frame)
                frame_count += 1
                
                # è¾“å‡ºè¯»å–è¿›åº¦
                if frame_count % 30 == 0:  # æ¯30å¸§è¾“å‡ºä¸€æ¬¡è¿›åº¦
                    progress = int((frame_count / total_frames) * 50)  # å‰åŠéƒ¨åˆ†è¿›åº¦(0-50%)
                    print(f"progress:{progress}%")
                
                if len(batch_frames) >= args.batch_frames or frame_count == total_frames:
                    print(f"\nprogress:æ­£åœ¨å¤„ç†ç¬¬ {batch_count + 1} æ‰¹, å¸§æ•°èŒƒå›´: {batch_count * args.batch_frames} - {frame_count}")
                    coords = process_video_batch(batch_frames, face_imgs_path, batch_count * args.batch_frames)
                    all_coords.extend(coords)
                    batch_frames = []
                    batch_count += 1
                    
                    # è¾“å‡ºæ‰¹æ¬¡å¤„ç†è¿›åº¦
                    progress = 50 + int((batch_count * args.batch_frames / total_frames) * 50)  # ååŠéƒ¨åˆ†è¿›åº¦(50-100%)
                    print(f"progress:{progress}%")
            
            cap.release()
            
            print(f"progress:æ­£åœ¨å†™å…¥åæ ‡æ•°æ®åˆ°æ–‡ä»¶: {coords_path}")
            with open(coords_path, 'wb') as f:
                pickle.dump(all_coords, f)
            
            print(f"progress:å¤„ç†å®Œæˆ! å…±å¤„ç†äº† {frame_count} å¸§ï¼Œåˆ†ä¸º {batch_count} ä¸ªæ‰¹æ¬¡")
            print("progress:100%")
    except Exception as e:
        print(f"progress:å¤„ç†å¤±è´¥: {e}")
        raise e

